# -*- coding: utf-8 -*-
"""ML2023_01_numpy_pandas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MbKlJrJ_QH0l_pUZN-kLgyBL0q5ZRqyC
"""

"""
File: ML2023_01_numpy_pandas
Author: Fabio Gasparetti
Date: 2024-04-03

Description: NumPy & Pandas
"""

# Nel terminale attivare l'environment Anaconda e installare le librerie se occorre:
#
# https://www.anaconda.com/download

# conda create -n python3_11_7_uniroma3 python=3.11
# source activate python3_11_7_uniroma3

# conda install numpy
# conda install pandas

# Se non si impiega Anaconda:
#
# pip install pandas
# pip install numpy

# Per Colab i suddetti comandi sono inutili

import numpy as np
import pandas as pd
import os # per il filesystem

# Gli  NumPy sono  più flessibili dei normali elenchi di Python.
# Si chiamano ndarray perché possono avere un numero qualsiasi (n) di dimensioni (d).
# Possono contenere un insieme di elementi di uno stesso tipo di dati
# e possono essere vettori (monodimensionali) o matrici (multidimensionali).
# Gli array di NumPy consentono un accesso rapido agli elementi e una manipolazione efficiente dei dati.


# Inizializziamo una lista Python - tipo di dato base
list1 = [1,2,3,4]
print('list1: ', list1)

# Convertiamo la lista in un ndarray 1-dimensionale, con 1 riga e 4 colonne
array1 = np.array(list1)
print('array1: ',array1)

# Per ottenere un ndarray a 2 dimensioni, è sufficiente passare una lista di liste
list2 = [[1,2,3],[4,5,6]]
array2 = np.array(list2)
print('array2: ',array2)

# A 2x2 2d array shape for the arrays in the format (rows, columns)
shape = (2, 2)

# Random values
c = np.empty(shape)
print('c: ',c)
d = np.ones(shape)
print('d: ',d)
e = np.zeros(shape)
print('e: ',e)

a = np.array([1, 2, 3])
b = np.array([5, 6])
print (np.concatenate([a, b, b]))

a2 = np.array([[1, 2], [3, 4]])
b = np.array([[5, 6]])

# axis=0 - concatenate along rows
print ('np.concatenate:\n',np.concatenate((a2, b), axis=0))

# axis=1 - concatenate along columns, but first b needs to be transposed:
print ('b.T:\n',b.T)

print ('np.concatenate:\n',np.concatenate((a2, b.T), axis=1))

# Creating ndarray from list
c = np.array([[1., 2.,],[1., 2.]])
print ('c:',c)
# Creating new array in the shape of c, filled with 0
d = np.empty_like(c)
print ('d:',d)

# slice dei dati
a = np.asarray([[1,1,2,3,4], # 1st row
                [2,6,7,8,9], # 2nd row
                [3,6,7,8,9], # 3rd row
                [4,6,7,8,9], # 4th row
                [5,6,7,8,9]  # 5th row
              ])

b = np.asarray([[1,1],
                [1,1]])

# Select row in the format a[start:end], if start or end omitted it means all range.
y1 = a[:1]  # 1st row
print('y1: ',y1)
y2 = a[0:1] # 1st row
print('y2: ',y2)
y3 = a[2:5] # select rows from 3rd to 5th row
print('y3: ',y3)

# Select column in the format a[start:end, column_number]
x1 = a[:, -1] # -1 means first from the end
print('x1: ',x1)

x2 = a[:,1:3] # select cols from 2nd col until 3rd
print('x2: ',x2)

# 1d arrays
print (np.append(a, a2))
# >> [1 2 3 1 2 3 4]

print (np.append(a, a))
# >> [1 2 3 1 2 3]

# 2d arrays – both arrays must match the shape of rows:
print (np.append(a2, b, axis=0))

print (np.append(a2, b.T, axis=1))

a = np.array([1, 2, 3])
b = np.array([5, 6])

# 1d arrays:

# Take a sequence of arrays and stack them horizontally to make a single array.
# Equivalent to np.concatenate(tup, axis=1)
print (np.hstack([a, b]))

# Equivalent to np.concatenate(tup, axis=0) if tup contains arrays that are at
# least 2-dimensional.
print (np.vstack([a, a]))

a2 = np.array([[1, 2], [3, 4]])
b = np.array([[5, 6]])

print (np.hstack([a2,a2])) # arrays must match shape

print (np.vstack([a2, b]))

# 2d arrays:
print (np.hstack([a2,a2])) # arrays must match shape

print (np.vstack([a2, b]))

# Vediamo alcune operazioni utili per manipolare i dataset

# Durante la standardizzazizone "centriamo" i valori intorno allo 0
# tipicamente sottraendo il valore medio.
toyPrices = np.array([5,8,3,6])
mean = np.mean(toyPrices)
print ('mean: ',mean)
print ('toyPrices - mean: ',toyPrices - mean)

# il codice alternativo sulle liste è il seguente:
toyPrices = [5,8,3,6]
# print(toyPrices - 2) -- Not possible. Causes an error
for i in range(len(toyPrices)):
    toyPrices[i] -= 2
print(toyPrices)

# il parametro axis indica su quale asse elaborare il calcolo
# list2 ha dimensione 2x3
# axis=0 indica che il calcolo sarà fatto iterando ogni riga (e considerando tutti i valori singolarmente per colonna)
# se si omette axis, la struttura è "flattened" e il calcolo è esteso a tutti i valori
mean0 = np.mean(list2, axis=0)
mean1 = np.mean(list2, axis=1)
print ('mean0: ', mean0)
print ('mean1: ', mean1)

# Creiamo una Series con un NumPy array e un sistema di indicizzazione di default
ages = np.array([13,25,19])
series1 = pd.Series(ages)
print ('series1:\n', series1)

# Ora usiamo una indicizzazione basata su stringhe
ages = np.array([13,25,19])
series1 = pd.Series(ages,index=['Emma', 'Swetha', 'Serajh'])
print ('series1:\n', series1)

# Creiamo un DataFrame utilizzando un elenco di liste in Python.
# Ogni elenco annidato rappresenta i dati di una riga del DataFrame.
# Utilizziamo la parola chiave columns per passare l'elenco dei nomi
# delle nostre colonne personalizzate.
dataf = pd.DataFrame([
    ['John Smith','123 Main St',34],
    ['Jane Doe', '456 Maple Ave',28],
    ['Joe Schmo', '789 Broadway',51]
    ],
    columns=['name','address','age'])
print ('dataf:\n',dataf)

# sostituisce l'indice di default con i valori di una colonna
dataf.set_index('name')

# Inizializziamo il DataFrame con un dizionario
dataf = pd.DataFrame({'name':['John Smith','Jane Doe','Joe Schmo'],
                      'address':['123 Main St','456 Maple Ave','789 Broadway'],
                      'age':[34,28,51]})
print ('dataf:\n',dataf)

# Carichiamo i dati a partire da un file csv

df = pd.read_csv("https://raw.githubusercontent.com/noahgift/regression-concepts/master/height-weight-25k.csv")

# uso r prima della stringa per evitare l'escaping dei backslashes
#data_path = r'ml2023/datasets/SOCR-HeightWeight.csv'
#df = pd.read_csv(data_path)

# Per le innumerevoli opzioni di lettura:
# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html

# di default la prima riga è considerata come header
# per definire le etichette delle colonne

df.head()

df.tail()

df.describe()

df.dtypes

# numero di N/A
df.isna().sum()

df=df.drop('Weight-Pounds',axis= 1)
df.tail()

df['Height-Inches'].max()



# I/O su file base

a2 = np.array([
    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],
    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],
    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],
    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],
    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1],
    [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1]
])

np.savetxt('test.txt', a2, delimiter=',')
a2_new = np.loadtxt('test.txt', delimiter=',')

# per matrici sparse

from sklearn.datasets import dump_svmlight_file, load_svmlight_file

matrix = [
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2],
    [1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 2],
    [1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 2]
]

labels = [1,1,1,1,1,2,2]


dump_svmlight_file(matrix, labels, 'svmlight.txt', zero_based=True)

# The file looks like this:

# 1 0:1 13:1 14:2
# 1 0:1 13:1 14:2
# 1 0:1 13:1 14:2
# 1 0:1 13:1 14:2
# 1 0:1 13:1 14:2
# 2 0:1 5:3 13:1 14:2
# 2 0:1 5:3 13:1 14:2

svm_loaded = load_svmlight_file('svmlight.txt', zero_based=True)